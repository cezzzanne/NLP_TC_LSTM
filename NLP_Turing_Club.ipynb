{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Turing_Club.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "rocD5aB9qavg",
        "colab_type": "code",
        "outputId": "78b533bd-be1c-4754-8c1c-6d3bab855238",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Keras \n",
        "import keras.utils as ku \n",
        "# The Layers we will Use\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "# Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# Our model\n",
        "from keras.models import Sequential\n",
        "# To address overfitting\n",
        "from keras.callbacks import EarlyStopping\n",
        "# To enable sequencing in our data\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "# Seeds for reproducibility\n",
        "from tensorflow import set_random_seed\n",
        "from numpy.random import seed\n",
        "set_random_seed(2)\n",
        "seed(1)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "oPIKRp7Vq_Xs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the data from your files\n",
        "text = open(\"kanye.txt\").read()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rsnak5AwrJkk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# See what it looks like, get the first 50 characters\n",
        "text[0:50]\n",
        "# Safe to say Kanye is a bit over the top"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7nwToC2mrN02",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# You can see we have a lot of \\n characters. This is meant to portray when a new line starts\n",
        "# So we want to split all of the sentences we have in order to avoid \\n characters as well as to get a more definite set of sentences\n",
        "splitted_text = text.split(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_wBYtG4-ryaF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualize how this looks\n",
        "splitted_text[0:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ScQZgY4wr4ut",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We still need to clean our text as it may contain characters we are not used to such as Ã¨ or more\n",
        "# We also want to convert everything to lower case\n",
        "def remove_unwanted_text(new_text):\n",
        "    new_text = \"\".join(x for x in new_text if x not in string.punctuation).lower()\n",
        "    # ignore this line\n",
        "    new_text = new_text.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "    return new_text \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M3K4eeT0sH2O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We now use our remove function on all our lines\n",
        "final_text = [remove_unwanted_text(x) for x in splitted_text]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9HSbLZCCtJ97",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualize it once again\n",
        "final_text[0:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "maPvsJwUtaDd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We know want to find a way in which to \"encode\" our words to numbers. That is, our model will only be able to recognize numbers. If we assign a specific number to each word then our algorithm will be able to learn!"
      ]
    },
    {
      "metadata": {
        "id": "u8nyJ_1jtpA-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Keras has a great way to do this with it's Tokenizer Object\n",
        "# This gives us access to the tokenizer capabilities from Keras\n",
        "tokenizer = Tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R7wPnKnrtw6K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now we encode our text with the tokenizer object\n",
        "tokenizer.fit_on_texts(final_text)\n",
        "# Try and tokenize our first sentece\n",
        "token_list = tokenizer.texts_to_sequences([final_text[0]])[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DP8TH6zot_-3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Visualize it\n",
        "print(token_list)\n",
        "print(final_text[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m62i5988uuc_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can see each word has become a unique number "
      ]
    },
    {
      "metadata": {
        "id": "6_UlonI-uCtd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now we do that for all of our sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OPNSG2Fyu3AB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_sequences(text):\n",
        "    # encode our words\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    # how many words we have in total ( + 1 because it starts at 0)\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "    ## convert data to sequence\n",
        "    # i.e, the text: \"hello new world will\" become the sequence:  hello -> hello new -> hello new world\n",
        "    sequences = []\n",
        "    for sentence in text:\n",
        "        # like before, we create a sequence of tokens for each sentence\n",
        "        token_sentences = tokenizer.texts_to_sequences([sentence])[0]\n",
        "        for i in range(1, len(token_sentences)):\n",
        "            # For each token (word) in our sentence we create an array with the token and its previous tokens\n",
        "            sequence = token_sentences[:i+1]\n",
        "            # Add that sequence to our array of sequences\n",
        "            sequences.append(sequence)\n",
        "    # Return our total sequences and the total number of words in our text\n",
        "    return sequences, total_words\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3mMWhoSEv61M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Give our function get_sequences our kanye text\n",
        "sequences, total_words = get_sequences(final_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "37JM_ZA-wPI9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# See how many UNIQUE words we have\n",
        "print(total_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ieodEbi3wYMY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Check our first 10 sequences\n",
        "sequences[0:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-kYyTew_wdER",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compare to our first 10 sentences \n",
        "final_text[:2]\n",
        "# Try and find patterns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tvIUR93Pwl5Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def padded_sequences(sequences):\n",
        "  # We need to have a fixed length for our sequences so the model can learn. We can't give it diffent size of inputs each time we run it!\n",
        "  # So we extract the max length and use that one. Shorter sequences will just use 0's where they don't have words\n",
        "    max_sequence_length = max([len(x) for x in sequences])\n",
        "    # Now we have to reshape our sequences to fit to this new lentgh\n",
        "    # Thankfully keras has the function pad_sequences that does this\n",
        "    # We then make it an array by calling np.array(padded_sequences)\n",
        "    sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_length, padding='pre'))\n",
        "    \n",
        "    # Now we split our sequences into data and labels\n",
        "    # for the phrase \"hello new world\"\n",
        "    # we will have the seuqences and labels: \n",
        "    # hello -> new\n",
        "    # hello new -> world\n",
        "    # Where each label is the next word we are trying to predict based on the sequence\n",
        "    data = sequences[:,:-1]\n",
        "    # So our data will be all the words up to the last one\n",
        "    label = sequences[:,-1]\n",
        "    # Our label will be our last word\n",
        "    # We don't want to assign greater importance to certain words just because they have a bigger number\n",
        "    # So we make them all arrays of 0 and 1. \n",
        "    # Each one of our labels will have a specific value\n",
        "    # i.e, hello can be [0, 0, 0, ..... ,  1] \n",
        "    # the length depends on the number of words we can have\n",
        "    \n",
        "    label = ku.to_categorical(label, num_classes=total_words)\n",
        "    return data, label, max_sequence_length\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zM3C2SvEzj5f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data, label, max_sequence_length = padded_sequences(sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aF0ArNGQznDf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now visualize our first sequence\n",
        "print(data[1])\n",
        "print(sequences[0])\n",
        "# We see we have a bunch of 0's before and after (this is the padding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jrXTDFGB0UhQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Now We Build The Model"
      ]
    },
    {
      "metadata": {
        "id": "6XPkIyGBz1PH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Declare a sequential model\n",
        "model = Sequential()\n",
        "# Add a layer to the model (Embedding) that will allow us to take the inputs\n",
        "model.add(Embedding(total_words, 10, input_length=max_sequence_length - 1)) # because its not 0-based\n",
        "# Add an LSTM Layer with 100 units\n",
        "model.add(LSTM(100))\n",
        "# Add another layer (our output layer) with softmax actiavtion\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "# Compile model with adam optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "adX7QhOFz8Mv",
        "colab_type": "code",
        "outputId": "fc4b784c-7d9a-4c3f-d019-3bca957ffdd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "# See what the model looks like\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 18, 10)            49380     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               44400     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4938)              498738    \n",
            "=================================================================\n",
            "Total params: 592,518\n",
            "Trainable params: 592,518\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L3In8205z9gP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now train it with our sequences and labels 100 times. verbose is just how we want to see the progress\n",
        "# CAUTION: THIS WILL TAKE  ~3 HOURS TO RUN USING GOOGOLE COLLAB'S GPU\n",
        "model.fit(data, label, epochs=100, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "keIXC0KG18Os",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nevertheless, I took the time to run it and we can see the ouputs here. **This Part will not run locally on your computer because you do not have the file model_with_verses2.h5. This file will be uploaded to the Turing Club FB page so you can test it out**"
      ]
    },
    {
      "metadata": {
        "id": "lEhNCwH71mZK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model('model_with_verses2.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ioJS_mJ32fmj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This function generates the text. Disregard it. **Taken from Stack Overflow."
      ]
    },
    {
      "metadata": {
        "id": "a-M5C3A42Tmz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = model.predict_classes(token_list, verbose=0)\n",
        "        \n",
        "        output_word = \"\"\n",
        "        for word,index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \"+output_word\n",
        "    return seed_text.title()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WNZ3vSvb2j48",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Put your input here! in the first parameter put the text you want to start with, second, the number of words to print"
      ]
    },
    {
      "metadata": {
        "id": "Kzd_EYFr2eAE",
        "colab_type": "code",
        "outputId": "b53e297d-e87a-4944-e266-2fb37ca0b0d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print (generate_text(\"How\", 15, model, max_sequence_length))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How Anything A Cause I Right You Leave How Do Jesus This Supposed A Dude The\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9UoO4pQd2rBH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The eminem one\n",
        "model = tf.keras.models.load_model('model_with_eminem.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Atit2jEw2-5l",
        "colab_type": "code",
        "outputId": "b9c4440b-8929-4db8-934d-1ecdd5214a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print (generate_text(\"Go\", 15, model, 33))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go The Say Tv Pryor You Slaves Mistakes But You Ups Ghetto She Go To Wait\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Dh1dNuw3kvX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We could make these models much better if I your're more patient and are willing to wait 6-7 hours for them to train on much more data.\n",
        "For now these seem like pretty good results\n",
        "\n",
        "Thank you for coming!"
      ]
    },
    {
      "metadata": {
        "id": "r6zz3seW31DT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}